# ä¸šåŠ¡ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ

## ğŸ“Š ç›‘æ§ç³»ç»Ÿæ¦‚è¿°

### ç›‘æ§ç›®æ ‡

å»ºç«‹å…¨é¢çš„ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿï¼Œå®æ—¶ç›‘æ§å¹³å°è¿è¡ŒçŠ¶æ€ã€ç”¨æˆ·è¡Œä¸ºã€AIæœåŠ¡æ€§èƒ½ç­‰å…³é”®æŒ‡æ ‡ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šè¿è¡Œå’Œç”¨æˆ·ä½“éªŒã€‚

## ğŸ¯ ç›‘æ§æŒ‡æ ‡ä½“ç³»

### 1. ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡

#### 1.1 HTTPè¯·æ±‚æŒ‡æ ‡

- **è¯·æ±‚æ€»æ•°** (http_requests_total)
- **è¯·æ±‚å“åº”æ—¶é—´** (http_request_duration_seconds)
- **é”™è¯¯ç‡** (http_errors_rate)
- **å¹¶å‘è¿æ¥æ•°** (http_concurrent_connections)

#### 1.2 æ•°æ®åº“æŒ‡æ ‡

- **æŸ¥è¯¢å“åº”æ—¶é—´** (db_query_duration_seconds)
- **è¿æ¥æ± ä½¿ç”¨ç‡** (db_connection_pool_usage)
- **æ…¢æŸ¥è¯¢æ•°é‡** (db_slow_queries_total)
- **æ­»é”æ•°é‡** (db_deadlocks_total)

#### 1.3 Redisç¼“å­˜æŒ‡æ ‡

- **ç¼“å­˜å‘½ä¸­ç‡** (cache_hit_rate)
- **ç¼“å­˜å¤§å°** (cache_size_bytes)
- **ç¼“å­˜æ“ä½œå»¶è¿Ÿ** (cache_operation_duration_seconds)
- **å†…å­˜ä½¿ç”¨ç‡** (redis_memory_usage_ratio)

### 2. ä¸šåŠ¡å…³é”®æŒ‡æ ‡

#### 2.1 ç”¨æˆ·æ´»è·ƒæŒ‡æ ‡

- **æ—¥æ´»è·ƒç”¨æˆ·** (daily_active_users)
- **æœˆæ´»è·ƒç”¨æˆ·** (monthly_active_users)
- **æ–°ç”¨æˆ·æ³¨å†Œæ•°** (new_users_registered)
- **ç”¨æˆ·ç•™å­˜ç‡** (user_retention_rate)

#### 2.2 AIæœåŠ¡ä½¿ç”¨æŒ‡æ ‡

- **AIä»»åŠ¡æäº¤æ•°** (ai_tasks_submitted_total)
- **AIä»»åŠ¡æˆåŠŸç‡** (ai_task_success_rate)
- **AIä»»åŠ¡å¹³å‡å¤„ç†æ—¶é—´** (ai_task_duration_avg)
- **å„æœåŠ¡ä½¿ç”¨é‡åˆ†å¸ƒ** (ai_service_usage_distribution)

#### 2.3 ç§¯åˆ†ç³»ç»ŸæŒ‡æ ‡

- **æ€»ç§¯åˆ†æ¶ˆè´¹** (credits_consumed_total)
- **å¹³å‡ç”¨æˆ·ç§¯åˆ†ä½™é¢** (avg_user_credits)
- **å……å€¼é‡‘é¢** (credits_purchased_total)
- **ç§¯åˆ†è½¬åŒ–ç‡** (credit_conversion_rate)

### 3. é”™è¯¯å’Œå¼‚å¸¸æŒ‡æ ‡

#### 3.1 ç³»ç»Ÿé”™è¯¯

- **åº”ç”¨é”™è¯¯æ•°** (application_errors_total)
- **AIæœåŠ¡è°ƒç”¨å¤±è´¥** (ai_service_failures_total)
- **æ”¯ä»˜å¤„ç†å¤±è´¥** (payment_failures_total)
- **æ–‡ä»¶ä¸Šä¼ å¤±è´¥** (file_upload_failures_total)

#### 3.2 å®‰å…¨æŒ‡æ ‡

- **ç™»å½•å¤±è´¥æ¬¡æ•°** (login_failures_total)
- **APIæ»¥ç”¨æ£€æµ‹** (api_abuse_detected)
- **å¼‚å¸¸è®¿é—®æ¨¡å¼** (suspicious_access_patterns)

## ğŸ› ï¸ ç›‘æ§ç³»ç»Ÿæ¶æ„

### ç³»ç»Ÿæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        åº”ç”¨æœåŠ¡å±‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   FastAPI       â”‚  â”‚   AI Services   â”‚  â”‚   Database      â”‚ â”‚
â”‚  â”‚   åº”ç”¨æœåŠ¡       â”‚  â”‚   AIæœåŠ¡ç›‘æ§     â”‚  â”‚   æ•°æ®åº“ç›‘æ§     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        æŒ‡æ ‡æ”¶é›†å±‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Prometheus    â”‚  â”‚    Grafana      â”‚  â”‚    Alertmanager â”‚ â”‚
â”‚  â”‚   æŒ‡æ ‡æ”¶é›†       â”‚  â”‚    å¯è§†åŒ–       â”‚  â”‚    å‘Šè­¦ç®¡ç†      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        é€šçŸ¥æ¸ é“å±‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     é‚®ä»¶        â”‚  â”‚     å¾®ä¿¡        â”‚  â”‚     é’‰é’‰        â”‚ â”‚
â”‚  â”‚    Email        â”‚  â”‚   WeChat        â”‚  â”‚   DingTalk      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ å®æ–½æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šPrometheusæŒ‡æ ‡æ”¶é›†

#### 1.1 å®‰è£…ä¾èµ–

```python
# requirements.txt æ·»åŠ 
prometheus-client==0.20.0
```

#### 1.2 æŒ‡æ ‡å®šä¹‰æ¨¡å—

```python
# backend/open_webui/utils/metrics.py
from prometheus_client import Counter, Histogram, Gauge, Enum, Info
from functools import wraps
import time
from typing import Dict, Any

# =================== HTTPè¯·æ±‚æŒ‡æ ‡ ===================
HTTP_REQUESTS_TOTAL = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status_code', 'user_role']
)

HTTP_REQUEST_DURATION = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration in seconds',
    ['method', 'endpoint'],
    buckets=[0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
)

HTTP_CONCURRENT_CONNECTIONS = Gauge(
    'http_concurrent_connections',
    'Current number of concurrent connections'
)

# =================== æ•°æ®åº“æŒ‡æ ‡ ===================
DB_QUERY_DURATION = Histogram(
    'db_query_duration_seconds',
    'Database query duration in seconds',
    ['table', 'operation'],
    buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1.0]
)

DB_CONNECTION_POOL_SIZE = Gauge(
    'db_connection_pool_size',
    'Database connection pool size'
)

DB_CONNECTION_POOL_USAGE = Gauge(
    'db_connection_pool_usage',
    'Database connection pool usage'
)

# =================== ç¼“å­˜æŒ‡æ ‡ ===================
CACHE_OPERATIONS_TOTAL = Counter(
    'cache_operations_total',
    'Total cache operations',
    ['operation', 'result']  # operation: get/set/delete, result: hit/miss/success/error
)

CACHE_HIT_RATE = Gauge(
    'cache_hit_rate',
    'Cache hit rate percentage'
)

# =================== ä¸šåŠ¡æŒ‡æ ‡ ===================
ACTIVE_USERS = Gauge(
    'active_users_current',
    'Current number of active users'
)

AI_TASKS_TOTAL = Counter(
    'ai_tasks_total',
    'Total AI tasks submitted',
    ['service', 'status', 'user_role']  # service: midjourney/flux/etc, status: success/failed/pending
)

AI_TASK_DURATION = Histogram(
    'ai_task_duration_seconds',
    'AI task processing duration',
    ['service', 'mode'],
    buckets=[1, 5, 10, 30, 60, 120, 300, 600, 1200]
)

CREDITS_OPERATIONS = Counter(
    'credits_operations_total',
    'Total credits operations',
    ['operation', 'user_role']  # operation: consume/refund/purchase
)

CREDITS_BALANCE = Histogram(
    'user_credits_balance',
    'User credits balance distribution',
    buckets=[0, 10, 50, 100, 500, 1000, 5000, float('inf')]
)

# =================== é”™è¯¯æŒ‡æ ‡ ===================
APPLICATION_ERRORS = Counter(
    'application_errors_total',
    'Total application errors',
    ['error_type', 'component']
)

SECURITY_EVENTS = Counter(
    'security_events_total',
    'Security-related events',
    ['event_type', 'severity']  # login_failure, api_abuse, etc.
)

# =================== ç³»ç»Ÿä¿¡æ¯ ===================
SYSTEM_INFO = Info(
    'system_info',
    'System information'
)
```

### æ–¹æ¡ˆ2ï¼šç›‘æ§è£…é¥°å™¨å’Œä¸­é—´ä»¶

#### 2.1 HTTPè¯·æ±‚ç›‘æ§ä¸­é—´ä»¶

```python
# backend/open_webui/utils/monitoring_middleware.py
from fastapi import Request, Response
from starlette.middleware.base import BaseHTTPMiddleware
import time
from .metrics import HTTP_REQUESTS_TOTAL, HTTP_REQUEST_DURATION, HTTP_CONCURRENT_CONNECTIONS

class MetricsMiddleware(BaseHTTPMiddleware):
    """æŒ‡æ ‡æ”¶é›†ä¸­é—´ä»¶"""

    def __init__(self, app):
        super().__init__(app)
        self.active_requests = 0

    async def dispatch(self, request: Request, call_next):
        # è®°å½•å¹¶å‘è¿æ¥æ•°
        self.active_requests += 1
        HTTP_CONCURRENT_CONNECTIONS.set(self.active_requests)

        # è®°å½•è¯·æ±‚å¼€å§‹æ—¶é—´
        start_time = time.time()

        # è·å–ç”¨æˆ·è§’è‰²ï¼ˆå¦‚æœå·²è®¤è¯ï¼‰
        user_role = "anonymous"
        if hasattr(request.state, 'user'):
            user_role = getattr(request.state.user, 'role', 'user')

        try:
            # å¤„ç†è¯·æ±‚
            response = await call_next(request)

            # è®°å½•æŒ‡æ ‡
            duration = time.time() - start_time

            HTTP_REQUESTS_TOTAL.labels(
                method=request.method,
                endpoint=self._get_endpoint_name(request),
                status_code=response.status_code,
                user_role=user_role
            ).inc()

            HTTP_REQUEST_DURATION.labels(
                method=request.method,
                endpoint=self._get_endpoint_name(request)
            ).observe(duration)

            return response

        except Exception as e:
            # è®°å½•é”™è¯¯
            HTTP_REQUESTS_TOTAL.labels(
                method=request.method,
                endpoint=self._get_endpoint_name(request),
                status_code=500,
                user_role=user_role
            ).inc()

            APPLICATION_ERRORS.labels(
                error_type=type(e).__name__,
                component="http_middleware"
            ).inc()

            raise

        finally:
            # æ›´æ–°å¹¶å‘è¿æ¥æ•°
            self.active_requests -= 1
            HTTP_CONCURRENT_CONNECTIONS.set(self.active_requests)

    def _get_endpoint_name(self, request: Request) -> str:
        """è·å–ç«¯ç‚¹åç§°"""
        if hasattr(request, 'url') and hasattr(request.url, 'path'):
            path = request.url.path

            # ç®€åŒ–è·¯å¾„ä»¥å‡å°‘æ ‡ç­¾åŸºæ•°
            if path.startswith('/api/v1/'):
                parts = path.split('/')
                if len(parts) >= 4:
                    # /api/v1/service -> service
                    return parts[3]

            return path.rstrip('/')

        return "unknown"

# ä¸šåŠ¡æŒ‡æ ‡è£…é¥°å™¨
def monitor_ai_task(service: str):
    """AIä»»åŠ¡ç›‘æ§è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            user_role = "user"  # å¯ä»¥ä»å‚æ•°ä¸­è·å–

            try:
                result = await func(*args, **kwargs)

                # è®°å½•æˆåŠŸä»»åŠ¡
                AI_TASKS_TOTAL.labels(
                    service=service,
                    status="success",
                    user_role=user_role
                ).inc()

                duration = time.time() - start_time
                AI_TASK_DURATION.labels(
                    service=service,
                    mode="default"  # å¯ä»¥ä»å‚æ•°ä¸­è·å–
                ).observe(duration)

                return result

            except Exception as e:
                # è®°å½•å¤±è´¥ä»»åŠ¡
                AI_TASKS_TOTAL.labels(
                    service=service,
                    status="failed",
                    user_role=user_role
                ).inc()

                APPLICATION_ERRORS.labels(
                    error_type=type(e).__name__,
                    component=f"ai_service_{service}"
                ).inc()

                raise

        return wrapper
    return decorator

def monitor_credits_operation(operation: str):
    """ç§¯åˆ†æ“ä½œç›‘æ§è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            user_role = "user"  # å¯ä»¥ä»å‚æ•°ä¸­è·å–

            try:
                result = func(*args, **kwargs)

                CREDITS_OPERATIONS.labels(
                    operation=operation,
                    user_role=user_role
                ).inc()

                # å¦‚æœæ˜¯æ¶ˆè´¹æ“ä½œï¼Œè®°å½•ä½™é¢åˆ†å¸ƒ
                if operation == "consume" and hasattr(result, 'credit'):
                    CREDITS_BALANCE.observe(float(result.credit))

                return result

            except Exception as e:
                APPLICATION_ERRORS.labels(
                    error_type=type(e).__name__,
                    component="credits_system"
                ).inc()
                raise

        return wrapper
    return decorator
```

### æ–¹æ¡ˆ3ï¼šå‘Šè­¦è§„åˆ™é…ç½®

#### 3.1 Prometheuså‘Šè­¦è§„åˆ™

```yaml
# alerts/business_alerts.yml
groups:
  - name: business_critical
    rules:
      # HTTPé”™è¯¯ç‡å‘Šè­¦
      - alert: HighErrorRate
        expr: (rate(http_requests_total{status_code=~"5.."}[5m]) / rate(http_requests_total[5m])) > 0.05
        for: 2m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: 'High error rate detected'
          description: 'Error rate is {{ $value | humanizePercentage }} over the last 5 minutes'

      # å“åº”æ—¶é—´å‘Šè­¦
      - alert: SlowResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 3m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: 'Slow response time detected'
          description: '95th percentile response time is {{ $value }}s'

      # AIæœåŠ¡å¤±è´¥ç‡å‘Šè­¦
      - alert: AIServiceHighFailureRate
        expr: (rate(ai_tasks_total{status="failed"}[10m]) / rate(ai_tasks_total[10m])) > 0.1
        for: 5m
        labels:
          severity: critical
          team: ai_services
        annotations:
          summary: 'AI service failure rate is high'
          description: '{{ $labels.service }} service failure rate is {{ $value | humanizePercentage }}'

      # ç¼“å­˜å‘½ä¸­ç‡ä½å‘Šè­¦
      - alert: LowCacheHitRate
        expr: cache_hit_rate < 0.7
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: 'Cache hit rate is low'
          description: 'Cache hit rate is {{ $value | humanizePercentage }}'

      # ç”¨æˆ·æ´»è·ƒåº¦å¼‚å¸¸
      - alert: UnusualUserActivity
        expr: |
          (
            avg_over_time(active_users_current[1h]) 
            - 
            avg_over_time(active_users_current[1h] offset 1d)
          ) / avg_over_time(active_users_current[1h] offset 1d) > 0.5
        for: 10m
        labels:
          severity: info
          team: product
        annotations:
          summary: 'Unusual increase in user activity'
          description: 'Active users increased by {{ $value | humanizePercentage }} compared to yesterday'

  - name: system_resources
    rules:
      # æ•°æ®åº“è¿æ¥æ± å‘Šè­¦
      - alert: DatabaseConnectionPoolExhausted
        expr: db_connection_pool_usage / db_connection_pool_size > 0.9
        for: 2m
        labels:
          severity: critical
          team: database
        annotations:
          summary: 'Database connection pool nearly exhausted'
          description: 'Connection pool usage is {{ $value | humanizePercentage }}'

      # Rediså†…å­˜ä½¿ç”¨å‘Šè­¦
      - alert: RedisHighMemoryUsage
        expr: redis_memory_usage_ratio > 0.85
        for: 5m
        labels:
          severity: warning
          team: cache
        annotations:
          summary: 'Redis memory usage is high'
          description: 'Redis memory usage is {{ $value | humanizePercentage }}'

  - name: security
    rules:
      # ç™»å½•å¤±è´¥å‘Šè­¦
      - alert: HighLoginFailureRate
        expr: rate(security_events_total{event_type="login_failure"}[5m]) > 10
        for: 2m
        labels:
          severity: warning
          team: security
        annotations:
          summary: 'High login failure rate detected'
          description: 'Login failure rate is {{ $value }} per second'

      # APIæ»¥ç”¨å‘Šè­¦
      - alert: APIAbuseDetected
        expr: rate(security_events_total{event_type="api_abuse"}[1m]) > 0
        for: 0m
        labels:
          severity: critical
          team: security
        annotations:
          summary: 'API abuse detected'
          description: 'API abuse detected at rate {{ $value }} per second'
```

### æ–¹æ¡ˆ4ï¼šGrafanaä»ªè¡¨æ¿

#### 4.1 ä¸šåŠ¡ä»ªè¡¨æ¿é…ç½®

```json
{
	"dashboard": {
		"title": "WXIAI ä¸šåŠ¡ç›‘æ§ä»ªè¡¨æ¿",
		"panels": [
			{
				"title": "å®æ—¶ç”¨æˆ·æ´»è·ƒ",
				"type": "stat",
				"targets": [
					{
						"expr": "active_users_current",
						"legendFormat": "å½“å‰æ´»è·ƒç”¨æˆ·"
					}
				]
			},
			{
				"title": "AIä»»åŠ¡æˆåŠŸç‡",
				"type": "stat",
				"targets": [
					{
						"expr": "rate(ai_tasks_total{status=\"success\"}[5m]) / rate(ai_tasks_total[5m])",
						"legendFormat": "æˆåŠŸç‡"
					}
				]
			},
			{
				"title": "å„AIæœåŠ¡ä½¿ç”¨é‡",
				"type": "piechart",
				"targets": [
					{
						"expr": "sum by (service) (rate(ai_tasks_total[1h]))",
						"legendFormat": "{{ service }}"
					}
				]
			},
			{
				"title": "APIå“åº”æ—¶é—´è¶‹åŠ¿",
				"type": "timeseries",
				"targets": [
					{
						"expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
						"legendFormat": "95th percentile"
					},
					{
						"expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
						"legendFormat": "50th percentile"
					}
				]
			},
			{
				"title": "ç¼“å­˜å‘½ä¸­ç‡",
				"type": "timeseries",
				"targets": [
					{
						"expr": "cache_hit_rate",
						"legendFormat": "å‘½ä¸­ç‡"
					}
				]
			}
		]
	}
}
```

## ğŸ“± å®æ–½å·¥å…·

### å·¥å…·1ï¼šç›‘æ§å¥åº·æ£€æŸ¥ç«¯ç‚¹

```python
# backend/open_webui/routers/monitoring.py
from fastapi import APIRouter, Depends
from prometheus_client import generate_latest, CONTENT_TYPE_LATEST
from fastapi.responses import Response
import json
from ..utils.metrics import *
from ..utils.auth import get_admin_user

router = APIRouter(prefix="/monitoring", tags=["monitoring"])

@router.get("/metrics")
async def prometheus_metrics():
    """PrometheusæŒ‡æ ‡ç«¯ç‚¹"""
    return Response(
        content=generate_latest(),
        media_type=CONTENT_TYPE_LATEST
    )

@router.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    checks = {
        "status": "healthy",
        "timestamp": time.time(),
        "checks": {
            "database": await check_database_health(),
            "redis": await check_redis_health(),
            "ai_services": await check_ai_services_health()
        }
    }

    # å¦‚æœæœ‰ä»»ä½•æ£€æŸ¥å¤±è´¥ï¼Œè¿”å›503
    if not all(check["healthy"] for check in checks["checks"].values()):
        return Response(
            content=json.dumps(checks),
            status_code=503,
            media_type="application/json"
        )

    return checks

@router.get("/stats", dependencies=[Depends(get_admin_user)])
async def monitoring_stats():
    """ç›‘æ§ç»Ÿè®¡ä¿¡æ¯"""
    from ..main import app

    stats = {
        "cache_stats": {},
        "active_connections": HTTP_CONCURRENT_CONNECTIONS._value._value,
        "total_requests": sum([
            metric._value._value for metric in HTTP_REQUESTS_TOTAL._metrics.values()
        ]),
        "ai_tasks_stats": {
            service: sum([
                metric._value._value
                for metric in AI_TASKS_TOTAL._metrics.values()
                if metric._labelvalues[0] == service
            ])
            for service in ["midjourney", "flux", "dreamwork", "jimeng", "kling"]
        }
    }

    # è·å–ç¼“å­˜ç»Ÿè®¡
    if hasattr(app.state, 'cache_manager'):
        stats["cache_stats"] = app.state.cache_manager.get_stats()

    return stats

async def check_database_health():
    """æ£€æŸ¥æ•°æ®åº“å¥åº·çŠ¶æ€"""
    try:
        from ..internal.db import get_db
        with get_db() as db:
            db.execute("SELECT 1")
        return {"healthy": True, "message": "Database is accessible"}
    except Exception as e:
        return {"healthy": False, "message": f"Database error: {str(e)}"}

async def check_redis_health():
    """æ£€æŸ¥Rediså¥åº·çŠ¶æ€"""
    try:
        from ..main import app
        if hasattr(app.state, 'cache_manager') and app.state.cache_manager.redis:
            await app.state.cache_manager.redis.ping()
            return {"healthy": True, "message": "Redis is accessible"}
        return {"healthy": True, "message": "Redis not configured"}
    except Exception as e:
        return {"healthy": False, "message": f"Redis error: {str(e)}"}

async def check_ai_services_health():
    """æ£€æŸ¥AIæœåŠ¡å¥åº·çŠ¶æ€"""
    # è¿™é‡Œå¯ä»¥æ·»åŠ å¯¹å„ä¸ªAIæœåŠ¡çš„å¥åº·æ£€æŸ¥
    return {"healthy": True, "message": "AI services check not implemented"}
```

### å·¥å…·2ï¼šå‘Šè­¦é€šçŸ¥ç³»ç»Ÿ

```python
# backend/open_webui/utils/alerting.py
import asyncio
import httpx
import json
from typing import Dict, Any, List
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.enabled_channels = config.get('enabled_channels', [])

    async def send_alert(self,
                        alert_name: str,
                        severity: str,
                        message: str,
                        details: Dict[str, Any] = None):
        """å‘é€å‘Šè­¦"""
        alert_data = {
            "alert_name": alert_name,
            "severity": severity,
            "message": message,
            "details": details or {},
            "timestamp": datetime.now().isoformat(),
            "source": "wxiai-platform"
        }

        # å¹¶å‘å‘é€åˆ°æ‰€æœ‰å¯ç”¨çš„é€šé“
        tasks = []

        if 'email' in self.enabled_channels:
            tasks.append(self._send_email_alert(alert_data))

        if 'webhook' in self.enabled_channels:
            tasks.append(self._send_webhook_alert(alert_data))

        if 'dingtalk' in self.enabled_channels:
            tasks.append(self._send_dingtalk_alert(alert_data))

        if tasks:
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # è®°å½•å‘é€ç»“æœ
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"Alert channel {i} failed: {result}")
                else:
                    logger.info(f"Alert sent successfully to channel {i}")

    async def _send_email_alert(self, alert_data: Dict[str, Any]):
        """å‘é€é‚®ä»¶å‘Šè­¦"""
        email_config = self.config.get('email', {})
        if not email_config.get('enabled'):
            return

        # å®ç°é‚®ä»¶å‘é€é€»è¾‘
        logger.info(f"Sending email alert: {alert_data['alert_name']}")

    async def _send_webhook_alert(self, alert_data: Dict[str, Any]):
        """å‘é€Webhookå‘Šè­¦"""
        webhook_config = self.config.get('webhook', {})
        if not webhook_config.get('enabled'):
            return

        url = webhook_config.get('url')
        if not url:
            return

        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    url,
                    json=alert_data,
                    headers={'Content-Type': 'application/json'},
                    timeout=10
                )
                response.raise_for_status()

        except Exception as e:
            logger.error(f"Webhook alert failed: {e}")
            raise

    async def _send_dingtalk_alert(self, alert_data: Dict[str, Any]):
        """å‘é€é’‰é’‰å‘Šè­¦"""
        dingtalk_config = self.config.get('dingtalk', {})
        if not dingtalk_config.get('enabled'):
            return

        webhook_url = dingtalk_config.get('webhook_url')
        if not webhook_url:
            return

        # æ ¼å¼åŒ–é’‰é’‰æ¶ˆæ¯
        severity_emoji = {
            'critical': 'ğŸš¨',
            'warning': 'âš ï¸',
            'info': 'â„¹ï¸'
        }

        message = {
            "msgtype": "markdown",
            "markdown": {
                "title": f"WXIAIå‘Šè­¦: {alert_data['alert_name']}",
                "text": f"""
## {severity_emoji.get(alert_data['severity'], 'ğŸ“¢')} {alert_data['alert_name']}

**å‘Šè­¦ç­‰çº§**: {alert_data['severity'].upper()}

**å‘Šè­¦ä¿¡æ¯**: {alert_data['message']}

**å‘ç”Ÿæ—¶é—´**: {alert_data['timestamp']}

**ç³»ç»Ÿæ¥æº**: {alert_data['source']}
"""
            }
        }

        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    webhook_url,
                    json=message,
                    headers={'Content-Type': 'application/json'},
                    timeout=10
                )
                response.raise_for_status()

        except Exception as e:
            logger.error(f"DingTalk alert failed: {e}")
            raise

# å…¨å±€å‘Šè­¦ç®¡ç†å™¨å®ä¾‹
alert_manager: AlertManager = None

def init_alert_manager(config: Dict[str, Any]):
    """åˆå§‹åŒ–å‘Šè­¦ç®¡ç†å™¨"""
    global alert_manager
    alert_manager = AlertManager(config)
    return alert_manager

async def send_business_alert(alert_name: str, severity: str, message: str, **kwargs):
    """å‘é€ä¸šåŠ¡å‘Šè­¦çš„ä¾¿æ·å‡½æ•°"""
    if alert_manager:
        await alert_manager.send_alert(alert_name, severity, message, kwargs)
    else:
        logger.warning(f"Alert manager not initialized, alert dropped: {alert_name}")
```

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### ç›‘æ§è¦†ç›–ç‡

- **ç³»ç»Ÿæ€§èƒ½**: 100%è¦†ç›–HTTPã€æ•°æ®åº“ã€ç¼“å­˜æŒ‡æ ‡
- **ä¸šåŠ¡æŒ‡æ ‡**: 100%è¦†ç›–ç”¨æˆ·ã€AIæœåŠ¡ã€ç§¯åˆ†ç³»ç»Ÿ
- **é”™è¯¯ç›‘æ§**: å…¨é¢çš„å¼‚å¸¸å’Œå®‰å…¨äº‹ä»¶ç›‘æ§
- **å‘Šè­¦å“åº”**: 2åˆ†é’Ÿå†…æ£€æµ‹åˆ°å…³é”®é—®é¢˜
- **å¯è§†åŒ–**: å®æ—¶ä»ªè¡¨æ¿å’Œå†å²è¶‹åŠ¿åˆ†æ

### è¿ç»´æ•ˆç‡æå‡

- **æ•…éšœå‘ç°æ—¶é—´**: ä»äººå·¥å‘ç°å‡å°‘åˆ°è‡ªåŠ¨æ£€æµ‹2åˆ†é’Ÿå†…
- **é—®é¢˜å®šä½æ•ˆç‡**: é€šè¿‡è¯¦ç»†æŒ‡æ ‡å¿«é€Ÿå®šä½é—®é¢˜æ ¹å› 
- **é¢„é˜²æ€§ç»´æŠ¤**: é€šè¿‡è¶‹åŠ¿åˆ†æé¢„é˜²æ½œåœ¨é—®é¢˜
- **å®¹é‡è§„åˆ’**: åŸºäºå†å²æ•°æ®è¿›è¡Œèµ„æºè§„åˆ’

---

**ç›‘æ§ç³»ç»Ÿå»ºè®¾å®Œæˆåï¼Œå°†å¤§å¤§æå‡ç³»ç»Ÿå¯è§‚æµ‹æ€§å’Œè¿ç»´æ•ˆç‡ï¼**

_æœ€åæ›´æ–°: 2025-08-24_
