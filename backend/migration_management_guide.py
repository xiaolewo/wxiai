#!/usr/bin/env python3
"""
æ•°æ®åº“è¿ç§»ç®¡ç†è§£å†³æ–¹æ¡ˆ
è§£å†³æ·»åŠ æ–°åŠŸèƒ½æ—¶å½±å“å…¶ä»–åŠŸèƒ½çš„æ ¹æœ¬é—®é¢˜

é—®é¢˜åˆ†æï¼š
1. é¡¹ç›®ä¸­å­˜åœ¨å¤šä¸ªæœªåŒæ­¥çš„è¿ç§»æ–‡ä»¶
2. ä¸åŒåŠŸèƒ½çš„è¿ç§»æ–‡ä»¶ç›¸äº’ä¾èµ–ä½†ä¸ä¸€è‡´
3. æ•°æ®åº“çŠ¶æ€ä¸è¿ç§»å†å²ä¸åŒ¹é…

è§£å†³æ–¹æ¡ˆï¼š
1. åˆ›å»ºç»Ÿä¸€çš„è¿ç§»çŠ¶æ€æ£€æŸ¥å·¥å…·
2. æä¾›è¿ç§»å†²çªè§£å†³æœºåˆ¶
3. å»ºç«‹æ ‡å‡†çš„åŠŸèƒ½æ·»åŠ æµç¨‹
"""

import sqlite3
import os
import sys
import json
from datetime import datetime
import subprocess
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MigrationManager:
    """æ•°æ®åº“è¿ç§»ç®¡ç†å™¨"""

    def __init__(
        self, db_path="data/webui.db", migrations_dir="open_webui/migrations/versions"
    ):
        self.db_path = db_path
        self.migrations_dir = Path(migrations_dir)
        self.ensure_db_directory()

    def ensure_db_directory(self):
        """ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)

    def get_current_db_version(self):
        """è·å–æ•°æ®åº“å½“å‰ç‰ˆæœ¬"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # æ£€æŸ¥alembic_versionè¡¨æ˜¯å¦å­˜åœ¨
            cursor.execute(
                """
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name='alembic_version';
            """
            )

            if not cursor.fetchone():
                conn.close()
                return None

            cursor.execute("SELECT version_num FROM alembic_version LIMIT 1;")
            result = cursor.fetchone()
            conn.close()

            return result[0] if result else None

        except Exception as e:
            logger.error(f"è·å–æ•°æ®åº“ç‰ˆæœ¬å¤±è´¥: {e}")
            return None

    def get_migration_files(self):
        """è·å–æ‰€æœ‰è¿ç§»æ–‡ä»¶ä¿¡æ¯"""
        migration_files = []

        if not self.migrations_dir.exists():
            logger.warning(f"è¿ç§»ç›®å½•ä¸å­˜åœ¨: {self.migrations_dir}")
            return migration_files

        for file_path in sorted(self.migrations_dir.glob("*.py")):
            if file_path.name == "__init__.py":
                continue

            try:
                # ä»æ–‡ä»¶åæå–ç‰ˆæœ¬ä¿¡æ¯
                filename = file_path.name
                if "_" in filename:
                    version = filename.split("_")[0]
                    description = "_".join(filename.split("_")[1:]).replace(".py", "")

                    migration_files.append(
                        {
                            "file": filename,
                            "version": version,
                            "description": description,
                            "path": str(file_path),
                        }
                    )

            except Exception as e:
                logger.warning(f"è§£æè¿ç§»æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

        return migration_files

    def get_actual_tables(self):
        """è·å–æ•°æ®åº“ä¸­å®é™…å­˜åœ¨çš„è¡¨"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute(
                """
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name NOT LIKE 'sqlite_%';
            """
            )

            tables = [row[0] for row in cursor.fetchall()]
            conn.close()
            return sorted(tables)

        except Exception as e:
            logger.error(f"è·å–è¡¨åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def get_table_columns(self, table_name):
        """è·å–è¡¨çš„åˆ—ä¿¡æ¯"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute(f"PRAGMA table_info({table_name});")
            columns = [row[1] for row in cursor.fetchall()]
            conn.close()
            return columns

        except Exception as e:
            logger.error(f"è·å–è¡¨ {table_name} åˆ—ä¿¡æ¯å¤±è´¥: {e}")
            return []

    def analyze_migration_state(self):
        """åˆ†æè¿ç§»çŠ¶æ€"""
        logger.info("ğŸ” å¼€å§‹åˆ†ææ•°æ®åº“è¿ç§»çŠ¶æ€...")

        current_version = self.get_current_db_version()
        migration_files = self.get_migration_files()
        actual_tables = self.get_actual_tables()

        analysis = {
            "current_version": current_version,
            "migration_files_count": len(migration_files),
            "actual_tables_count": len(actual_tables),
            "migration_files": migration_files,
            "actual_tables": actual_tables,
            "issues": [],
            "recommendations": [],
        }

        # æ£€æŸ¥ç‰ˆæœ¬ä¸€è‡´æ€§
        if not current_version:
            analysis["issues"].append("æ•°æ®åº“æ²¡æœ‰ç‰ˆæœ¬è®°å½•ï¼Œå¯èƒ½æœªåˆå§‹åŒ–Alembic")
            analysis["recommendations"].append(
                "è¿è¡Œ 'alembic stamp head' åˆå§‹åŒ–ç‰ˆæœ¬è®°å½•"
            )

        # æ£€æŸ¥å·²çŸ¥çš„é—®é¢˜è¡¨
        expected_tables = [
            "user",
            "auth",
            "config",
            "chat",
            "tag",
            "channel",
            "folder",
            "mj_tasks",
            "dreamwork_tasks",
            "kling_tasks",
            "jimeng_tasks",
            "flux_config",
            "flux_tasks",
            "flux_credits",
            "cloud_storage_config",
            "generated_files",
            "credit",
            "credit_log",
            "group",
        ]

        missing_tables = [
            table for table in expected_tables if table not in actual_tables
        ]
        if missing_tables:
            analysis["issues"].append(f"ç¼ºå¤±çš„è¡¨: {missing_tables}")
            analysis["recommendations"].append("è¿è¡Œæ•°æ®åº“ä¿®å¤è„šæœ¬æˆ–é‡æ–°æ‰§è¡Œè¿ç§»")

        # æ£€æŸ¥æ ¸å¿ƒè¡¨çš„å¿…éœ€å­—æ®µ
        table_required_columns = {
            "chat": ["id", "user_id", "title", "folder_id", "pinned", "meta"],
            "tag": ["id", "name", "user_id", "meta"],
            "user": ["id", "email", "name", "phone"],
        }

        for table, required_cols in table_required_columns.items():
            if table in actual_tables:
                actual_cols = self.get_table_columns(table)
                missing_cols = [col for col in required_cols if col not in actual_cols]
                if missing_cols:
                    analysis["issues"].append(f"è¡¨ {table} ç¼ºå¤±å­—æ®µ: {missing_cols}")
                    analysis["recommendations"].append(f"ä¸ºè¡¨ {table} æ·»åŠ ç¼ºå¤±å­—æ®µ")

        return analysis

    def create_migration_snapshot(self):
        """åˆ›å»ºå½“å‰è¿ç§»çŠ¶æ€å¿«ç…§"""
        logger.info("ğŸ“¸ åˆ›å»ºè¿ç§»çŠ¶æ€å¿«ç…§...")

        analysis = self.analyze_migration_state()
        snapshot = {
            "timestamp": datetime.now().isoformat(),
            "database_path": self.db_path,
            "analysis": analysis,
        }

        snapshot_file = (
            f"migration_snapshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )

        with open(snapshot_file, "w", encoding="utf-8") as f:
            json.dump(snapshot, f, indent=2, ensure_ascii=False)

        logger.info(f"âœ… å¿«ç…§å·²ä¿å­˜åˆ°: {snapshot_file}")
        return snapshot_file

    def reset_migration_state(self):
        """é‡ç½®è¿ç§»çŠ¶æ€ï¼ˆå±é™©æ“ä½œï¼‰"""
        logger.warning("âš ï¸ è¿™æ˜¯ä¸€ä¸ªå±é™©æ“ä½œï¼Œå°†é‡ç½®æ‰€æœ‰è¿ç§»çŠ¶æ€ï¼")

        response = input("ç¡®è®¤é‡ç½®è¿ç§»çŠ¶æ€ï¼Ÿè¾“å…¥ 'YES' ç¡®è®¤: ")
        if response != "YES":
            logger.info("æ“ä½œå·²å–æ¶ˆ")
            return False

        try:
            # å¤‡ä»½æ•°æ®åº“
            backup_path = (
                f"{self.db_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            )
            import shutil

            shutil.copy2(self.db_path, backup_path)
            logger.info(f"æ•°æ®åº“å·²å¤‡ä»½åˆ°: {backup_path}")

            # åˆ é™¤alembic_versionè¡¨
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("DROP TABLE IF EXISTS alembic_version;")
            conn.commit()
            conn.close()

            logger.info("âœ… è¿ç§»çŠ¶æ€å·²é‡ç½®")
            return True

        except Exception as e:
            logger.error(f"é‡ç½®è¿ç§»çŠ¶æ€å¤±è´¥: {e}")
            return False

    def fix_migration_conflicts(self):
        """ä¿®å¤è¿ç§»å†²çª"""
        logger.info("ğŸ”§ å¼€å§‹ä¿®å¤è¿ç§»å†²çª...")

        # é¦–å…ˆè¿è¡Œæ•°æ®åº“ä¿®å¤è„šæœ¬
        try:
            from fix_database_tables import fix_database_tables

            logger.info("è¿è¡Œæ•°æ®åº“è¡¨ä¿®å¤è„šæœ¬...")
            if fix_database_tables():
                logger.info("âœ… æ•°æ®åº“è¡¨ä¿®å¤å®Œæˆ")
            else:
                logger.error("âŒ æ•°æ®åº“è¡¨ä¿®å¤å¤±è´¥")
                return False
        except ImportError:
            logger.warning("æœªæ‰¾åˆ°æ•°æ®åº“ä¿®å¤è„šæœ¬ï¼Œè·³è¿‡...")

        # æ£€æŸ¥å¹¶ä¿®å¤Alembicç‰ˆæœ¬è®°å½•
        try:
            current_version = self.get_current_db_version()
            if not current_version:
                # è®¾ç½®ä¸ºæœ€æ–°çš„è¿ç§»ç‰ˆæœ¬
                migration_files = self.get_migration_files()
                if migration_files:
                    latest_version = migration_files[-1]["version"]

                    conn = sqlite3.connect(self.db_path)
                    cursor = conn.cursor()

                    # åˆ›å»ºalembic_versionè¡¨
                    cursor.execute(
                        """
                        CREATE TABLE IF NOT EXISTS alembic_version (
                            version_num VARCHAR(32) NOT NULL,
                            PRIMARY KEY (version_num)
                        );
                    """
                    )

                    # æ’å…¥æœ€æ–°ç‰ˆæœ¬
                    cursor.execute(
                        """
                        INSERT OR REPLACE INTO alembic_version (version_num) 
                        VALUES (?);
                    """,
                        (latest_version,),
                    )

                    conn.commit()
                    conn.close()

                    logger.info(f"âœ… å·²è®¾ç½®æ•°æ®åº“ç‰ˆæœ¬ä¸º: {latest_version}")

            return True

        except Exception as e:
            logger.error(f"ä¿®å¤è¿ç§»å†²çªå¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ æ•°æ®åº“è¿ç§»ç®¡ç†å·¥å…·")
    print("=" * 50)

    manager = MigrationManager()

    while True:
        print("\nå¯ç”¨æ“ä½œï¼š")
        print("1. åˆ†æè¿ç§»çŠ¶æ€")
        print("2. åˆ›å»ºçŠ¶æ€å¿«ç…§")
        print("3. ä¿®å¤è¿ç§»å†²çª")
        print("4. é‡ç½®è¿ç§»çŠ¶æ€ï¼ˆå±é™©ï¼‰")
        print("0. é€€å‡º")

        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (0-4): ").strip()

        if choice == "0":
            print("å†è§ï¼")
            break
        elif choice == "1":
            analysis = manager.analyze_migration_state()
            print(f"\nğŸ“Š è¿ç§»çŠ¶æ€åˆ†æ:")
            print(f"å½“å‰ç‰ˆæœ¬: {analysis['current_version']}")
            print(f"è¿ç§»æ–‡ä»¶æ•°: {analysis['migration_files_count']}")
            print(f"å®é™…è¡¨æ•°: {analysis['actual_tables_count']}")

            if analysis["issues"]:
                print(f"\nâš ï¸ å‘ç°é—®é¢˜:")
                for issue in analysis["issues"]:
                    print(f"  - {issue}")

            if analysis["recommendations"]:
                print(f"\nğŸ’¡ å»ºè®®:")
                for rec in analysis["recommendations"]:
                    print(f"  - {rec}")

        elif choice == "2":
            snapshot_file = manager.create_migration_snapshot()
            print(f"âœ… å¿«ç…§å·²åˆ›å»º: {snapshot_file}")

        elif choice == "3":
            if manager.fix_migration_conflicts():
                print("âœ… è¿ç§»å†²çªä¿®å¤å®Œæˆ")
            else:
                print("âŒ è¿ç§»å†²çªä¿®å¤å¤±è´¥")

        elif choice == "4":
            manager.reset_migration_state()

        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")


if __name__ == "__main__":
    main()
