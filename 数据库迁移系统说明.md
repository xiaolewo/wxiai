# 数据库迁移系统详细说明

## 🏗️ 项目架构概述

**wxiai-main** 是一个基于FastAPI + SQLAlchemy + Alembic的AI服务集成平台，主要功能包括：

- Flux AI图像生成服务
- 用户管理和权限控制
- 工具管理系统
- 积分和支付系统
- 多种AI模型集成（Midjourney、Kling、Jimeng等）

**核心技术栈：**

- Backend: FastAPI + SQLAlchemy + Alembic
- Frontend: SvelteKit
- Database: SQLite (生产环境可用PostgreSQL)
- Deployment: Docker + Docker Compose

## 🗄️ 数据库迁移系统架构

### 1. Alembic配置结构

```
backend/
├── open_webui/
│   ├── migrations/          # Alembic迁移目录
│   │   ├── env.py          # Alembic环境配置
│   │   ├── alembic.ini     # Alembic配置文件
│   │   └── versions/       # 迁移版本文件
│   ├── internal/
│   │   └── db.py           # 数据库连接和Base定义
│   ├── models/             # SQLAlchemy模型
│   │   ├── users.py        # 用户模型
│   │   ├── tools.py        # 工具模型
│   │   ├── flux.py         # Flux配置模型
│   │   └── ...
│   └── config.py           # 应用配置和迁移执行逻辑
```

### 2. 迁移执行流程

**应用启动时的自动迁移机制：**

```python
# config.py 中的迁移执行逻辑
def run_migrations():
    """运行Alembic迁移"""
    try:
        from alembic import command
        from alembic.config import Config

        alembic_cfg = Config(OPEN_WEBUI_DIR / "alembic.ini")
        migrations_path = OPEN_WEBUI_DIR / "migrations"
        alembic_cfg.set_main_option("script_location", str(migrations_path))

        # 三层迁移策略
        try:
            command.upgrade(alembic_cfg, "merge_heads_final")  # 尝试合并点
        except Exception:
            try:
                command.upgrade(alembic_cfg, "heads")          # 尝试所有heads
            except Exception:
                command.upgrade(alembic_cfg, "head")           # 最后尝试单head

    except Exception as e:
        # Fallback: 直接创建表结构
        from open_webui.internal.db import engine, Base
        Base.metadata.create_all(bind=engine)

def delayed_migration_execution():
    """延迟执行迁移，避免循环导入"""
    def run_delayed():
        time.sleep(1)  # 等待导入完成
        run_migrations()

    # 阻塞式执行，确保迁移完成后再启动应用
    migration_thread = threading.Thread(target=run_delayed, daemon=False)
    migration_thread.start()
    migration_thread.join(timeout=30)  # 最多等待30秒

# 应用启动时自动执行
delayed_migration_execution()
```

### 3. 三层保护机制

**第一层：Alembic自动迁移**

- 检测未执行的迁移文件
- 按版本依赖顺序执行
- 支持升级和降级操作

**第二层：直接创建表结构**

- 当Alembic迁移失败时触发
- 使用SQLAlchemy的`create_all()`创建所有表
- 确保基本的表结构存在

**第三层：运行时兼容处理**

- 在模型层面处理缺失的列
- ORM查询失败时自动降级到原生SQL
- 为缺失字段提供默认值

## 🔧 关键迁移文件说明

### 重要的迁移版本

```
migrations/versions/
├── 70c7b727736e_add_tool_access_control_column.py    # 工具访问控制列
├── ef6fab585ac1_add_user_phone_column.py             # 用户手机号列
├── 24e8f9a7b1c2_add_flux_model_credits_column.py     # Flux模型积分配置
├── abc123def456_add_cloud_urls_to_all_tasks.py       # 云存储URL列
└── merge_heads_final.py                              # 多头合并文件
```

### 典型迁移文件结构

```python
"""add_user_phone_column

Revision ID: ef6fab585ac1
Revises: 70c7b727736e
Create Date: 2025-08-18 12:15:17.101992
"""

def upgrade() -> None:
    """升级操作：添加新列"""
    connection = op.get_bind()
    inspector = sa.inspect(connection)

    if "user" in inspector.get_table_names():
        existing_columns = [col["name"] for col in inspector.get_columns("user")]

        with op.batch_alter_table("user", schema=None) as batch_op:
            if "phone" not in existing_columns:
                batch_op.add_column(sa.Column("phone", sa.String(), nullable=True))
                print("Added phone column to user table")
            else:
                print("phone column already exists in user table")

def downgrade() -> None:
    """降级操作：删除列（生产环境慎用）"""
    with op.batch_alter_table("user", schema=None) as batch_op:
        batch_op.drop_column("phone")
```

## 🛡️ 数据安全机制

### 1. 只添加不删除原则

**安全的迁移操作：**

```python
# ✅ 安全：添加新列
op.add_column('user', sa.Column('phone', sa.String(), nullable=True))

# ✅ 安全：添加新表
op.create_table('new_feature', ...)

# ✅ 安全：添加索引
op.create_index('ix_user_email', 'user', ['email'])
```

**禁止的危险操作：**

```python
# ❌ 危险：删除表
# op.drop_table('user')

# ❌ 危险：删除列
# op.drop_column('user', 'email')

# ❌ 危险：修改列类型（可能导致数据丢失）
# op.alter_column('user', 'age', type_=sa.String())
```

### 2. 向后兼容处理

每个模型都实现了向后兼容机制：

```python
# users.py 中的兼容处理示例
def get_users(self, filter=None, skip=None, limit=None):
    with get_db() as db:
        try:
            # 尝试正常ORM查询
            query = db.query(User)
            # ... 正常处理逻辑
            users = query.all()
            return {"users": [UserModel.model_validate(user) for user in users]}

        except Exception as e:
            if "no such column" in str(e) and "phone" in str(e):
                # 检测到phone列缺失，使用兼容模式
                logger.warning("phone列不存在，使用兼容模式查询users")

                # 使用原生SQL查询，跳过缺失的列
                result = db.execute(text("""
                    SELECT id, name, email, role, profile_image_url,
                           last_active_at, updated_at, created_at, api_key,
                           settings, info, oauth_sub
                    FROM user ORDER BY created_at DESC
                """)).fetchall()

                users = []
                for row in result:
                    user_dict = {
                        "id": row[0], "name": row[1], "email": row[2],
                        # ... 其他字段映射
                        "phone": None,  # 缺失字段设为默认值
                    }
                    users.append(UserModel.model_validate(user_dict))

                return {"users": users, "total": len(users)}
```

### 3. Session管理最佳实践

**正确的Session使用：**

```python
# ✅ 正确：在同一个Session中操作
with get_db() as db:
    config = db.query(FluxConfig).first()  # 在当前Session中查询
    if config:
        config.api_key = new_key              # 直接修改
        db.commit()                           # 提交更改

# ❌ 错误：跨Session操作
config = FluxConfigs.get_config()  # 来自其他Session
with get_db() as db:
    config.api_key = new_key        # 会导致Session错误
    db.commit()
```

## 🚀 部署场景处理

### 1. 全新部署（空数据库）

```
启动流程：
1. 检测数据库文件不存在
2. 执行所有迁移文件（从初始版本到最新）
3. 创建完整的表结构
4. 插入默认数据（如管理员账户）
5. 应用正常启动

日志示例：
INFO [alembic.runtime.migration] Running upgrade -> 7e5b5dc7342b, init
INFO [alembic.runtime.migration] Running upgrade 7e5b5dc7342b -> ca81bd47c050, add_config_table
...
INFO [alembic.runtime.migration] Running upgrade ef6fab585ac1 -> 24e8f9a7b1c2, add_flux_model_credits
✅ Tables created successfully
```

### 2. 更新部署（现有数据）

```
启动流程：
1. 检测现有数据库文件
2. 比较当前版本与目标版本
3. 执行增量迁移（只执行缺失的迁移）
4. 向后兼容处理确保旧数据正常访问
5. 应用正常启动，数据完整保留

日志示例：
INFO [alembic.runtime.migration] Current revision: 70c7b727736e
INFO [alembic.runtime.migration] Running upgrade 70c7b727736e -> ef6fab585ac1, add_user_phone_column
INFO [alembic.runtime.migration] Running upgrade ef6fab585ac1 -> 24e8f9a7b1c2, add_flux_model_credits
✅ Existing users: 1250, Existing chats: 5000+ (数据完整保留)
```

### 3. Docker环境特殊处理

```yaml
# docker-compose.yaml 配置
services:
  open-webui:
    volumes:
      - open-webui:/app/backend/data # 持久化数据卷
    environment:
      - DATABASE_URL=sqlite:////app/backend/data/webui.db
    entrypoint: ['/usr/local/bin/docker-entrypoint.sh']
    command: ['bash', 'start.sh']
```

```bash
# docker-entrypoint.sh 自动处理
#!/bin/bash
echo "🔧 Installing additional dependencies..."
if ! python -c "import cos_python_sdk_v5" 2>/dev/null; then
    pip install cos-python-sdk-v5==1.9.30
fi

echo "🔄 Starting database migrations..."
# 应用启动时会自动执行迁移

echo "🚀 Starting Open WebUI..."
exec "$@"
```

## 🔍 故障诊断和恢复

### 1. 迁移失败处理

```python
# config.py 中的故障恢复机制
try:
    run_migrations()  # 尝试Alembic迁移
except Exception as e:
    log.exception(f"Error running migrations: {e}")

    # 自动fallback到直接创建表
    try:
        log.info("Attempting to create tables directly")
        from open_webui.internal.db import engine, Base
        Base.metadata.create_all(bind=engine)
        log.info("Tables created successfully")
    except Exception as create_error:
        log.exception(f"Error creating tables directly: {create_error}")
```

### 2. 数据修复脚本

```python
# fix_db_startup.py 独立修复脚本
def run_migrations_sync():
    """同步执行数据库迁移"""
    try:
        print("🔄 开始执行数据库迁移...")

        from alembic import command
        from alembic.config import Config

        command.upgrade(alembic_cfg, "head")
        print("✅ 数据库迁移执行成功!")

    except Exception as e:
        print(f"❌ 迁移执行失败: {e}")

        # 尝试直接创建表
        try:
            from open_webui.internal.db import engine, Base
            Base.metadata.create_all(bind=engine)
            print("✅ 数据库表创建成功!")
        except Exception as create_error:
            print(f"❌ 表创建也失败: {create_error}")

# 使用方法
if __name__ == "__main__":
    success = run_migrations_sync()
    sys.exit(0 if success else 1)
```

## 📊 验证和监控

### 1. 迁移状态检查

```bash
# 检查当前迁移版本
python -m alembic -c backend/open_webui/alembic.ini current

# 查看迁移历史
python -m alembic -c backend/open_webui/alembic.ini history

# 查看待执行的迁移
python -m alembic -c backend/open_webui/alembic.ini show head
```

### 2. 数据完整性验证

```python
# 验证关键模型是否正常
def verify_database_integrity():
    try:
        from open_webui.models.users import Users
        from open_webui.models.tools import Tools
        from open_webui.models.flux import FluxConfigs

        # 测试用户模型
        users = Users.get_users(limit=1)
        print(f"✅ Users: {len(users.get('users', []))} found")

        # 测试工具模型
        tools = Tools.get_tools()
        print(f"✅ Tools: {len(tools)} found")

        # 测试Flux配置
        config = FluxConfigs.get_config()
        print(f"✅ Flux config: {'exists' if config else 'not configured'}")

        print("✅ Database integrity check passed!")
        return True

    except Exception as e:
        print(f"❌ Database integrity check failed: {e}")
        return False
```

## ⚙️ 配置和环境变量

### 关键配置项

```python
# 数据库配置
DATABASE_URL = "sqlite:///data/webui.db"  # 默认SQLite
# DATABASE_URL = "postgresql://user:pass@localhost/db"  # 生产环境可用PostgreSQL

# 迁移配置
ENABLE_AUTO_MIGRATION = True    # 启用自动迁移
MIGRATION_TIMEOUT = 30          # 迁移超时时间（秒）
ENABLE_FALLBACK_CREATE = True   # 启用fallback表创建

# 兼容性配置
ENABLE_BACKWARD_COMPATIBILITY = True  # 启用向后兼容
LOG_COMPATIBILITY_WARNINGS = True     # 记录兼容性警告
```

## 📝 最佳实践总结

### 1. 迁移开发规范

- **只添加不删除** - 生产环境绝不删除表或列
- **nullable=True** - 新列必须允许NULL
- **先测试后部署** - 在测试环境充分验证迁移
- **版本控制** - 迁移文件纳入Git管理

### 2. 部署策略

- **数据备份** - 重要更新前备份数据库
- **分阶段部署** - 先部署测试环境，再生产环境
- **监控日志** - 关注迁移执行日志和错误信息
- **回滚准备** - 准备回滚方案（通常是代码回滚）

### 3. 故障处理

- **日志分析** - 根据错误日志判断问题类型
- **兼容模式** - 利用向后兼容机制临时恢复服务
- **手动修复** - 使用fix_db_startup.py脚本手动修复
- **专家支持** - 复杂问题及时寻求技术支持

这个数据库迁移系统经过实战验证，能够处理从全新部署到复杂更新的各种场景，确保数据安全和系统稳定性。

## 🆕 新功能开发指南

### 添加新功能的标准流程

当需要为系统添加新功能时，遵循以下标准化流程确保数据迁移安全：

#### Step 1: 创建迁移文件

```bash
cd backend
python -m alembic revision -m "add_your_new_feature"
```

#### Step 2: 编写安全的迁移脚本

```python
# migrations/versions/xxx_add_new_feature.py
"""add_new_feature

Revision ID: xxx
Revises: previous_revision
Create Date: 2025-xx-xx xx:xx:xx.xxxxxx
"""

def upgrade() -> None:
    """升级操作：安全添加新功能的数据库结构"""
    connection = op.get_bind()
    inspector = sa.inspect(connection)

    # 检查目标表是否存在
    if "your_table" in inspector.get_table_names():
        existing_columns = [col["name"] for col in inspector.get_columns("your_table")]

        with op.batch_alter_table("your_table", schema=None) as batch_op:
            # 安全添加新列
            if "new_column" not in existing_columns:
                batch_op.add_column(sa.Column("new_column", sa.String(), nullable=True))
                print("Added new_column to your_table")
            else:
                print("new_column already exists in your_table")

            # 添加JSON配置列（如果需要）
            if "config_data" not in existing_columns:
                batch_op.add_column(sa.Column("config_data", sa.JSON, nullable=True))
                print("Added config_data to your_table")
    else:
        # 创建新表（全新功能）
        op.create_table(
            'your_table',
            sa.Column('id', sa.String(255), primary_key=True),
            sa.Column('user_id', sa.String(255), nullable=False, index=True),
            sa.Column('new_column', sa.String(), nullable=True),
            sa.Column('config_data', sa.JSON, nullable=True),
            sa.Column('created_at', sa.DateTime, nullable=False, server_default=sa.func.now()),
            sa.Column('updated_at', sa.DateTime, nullable=False, server_default=sa.func.now()),
        )
        print("Created new table: your_table")

def downgrade() -> None:
    """降级操作：生产环境慎用，通常留空"""
    # 生产环境不建议删除列或表，以防数据丢失
    pass
```

#### Step 3: 模型层向后兼容处理

```python
# models/your_model.py
class YourModel(Base):
    __tablename__ = "your_table"

    id = Column(String(255), primary_key=True)
    user_id = Column(String(255), nullable=False, index=True)
    # 现有列...
    new_column = Column(String(), nullable=True)  # 新功能列
    config_data = Column(JSON, nullable=True)     # 新功能配置

class YourModels:
    """数据库操作类，包含向后兼容处理"""

    @staticmethod
    def get_data(user_id: str = None):
        """获取数据 - 向后兼容处理"""
        with get_db() as db:
            try:
                # 尝试正常ORM查询
                query = db.query(YourModel)
                if user_id:
                    query = query.filter(YourModel.user_id == user_id)
                return query.all()

            except Exception as e:
                if "no such column" in str(e) and "new_column" in str(e):
                    # 检测到new_column列缺失，使用兼容模式
                    logger.warning("new_column列不存在，使用兼容模式查询")

                    # 使用原生SQL查询，跳过缺失的列
                    sql = """
                        SELECT id, user_id, existing_column1, existing_column2,
                               created_at, updated_at
                        FROM your_table
                    """
                    if user_id:
                        sql += " WHERE user_id = :user_id"
                        result = db.execute(text(sql), {"user_id": user_id}).fetchall()
                    else:
                        result = db.execute(text(sql)).fetchall()

                    # 手动构建对象列表
                    data_list = []
                    for row in result:
                        data_dict = {
                            "id": row[0],
                            "user_id": row[1],
                            "existing_column1": row[2],
                            "existing_column2": row[3],
                            "new_column": None,      # 缺失字段设为默认值
                            "config_data": {},       # 缺失配置设为空字典
                            "created_at": row[4],
                            "updated_at": row[5],
                        }
                        data_list.append(data_dict)

                    return data_list
                else:
                    # 其他类型错误，重新抛出
                    raise e

    @staticmethod
    def create_or_update(data_dict: dict):
        """创建或更新数据 - 向后兼容处理"""
        with get_db() as db:
            try:
                # 尝试正常操作
                existing = db.query(YourModel).filter(YourModel.id == data_dict.get("id")).first()

                if existing:
                    # 更新现有记录
                    for key, value in data_dict.items():
                        if hasattr(existing, key):
                            setattr(existing, key, value)
                else:
                    # 创建新记录
                    new_record = YourModel(**data_dict)
                    db.add(new_record)

                db.commit()
                return True

            except Exception as e:
                if "no such column" in str(e) and ("new_column" in str(e) or "config_data" in str(e)):
                    # 兼容模式：只更新现有字段
                    logger.warning("新字段不存在，使用兼容模式保存")

                    # 过滤掉不存在的字段
                    safe_data = {k: v for k, v in data_dict.items()
                               if k in ["id", "user_id", "existing_column1", "existing_column2"]}

                    if data_dict.get("id"):
                        # 更新操作
                        db.execute(text("""
                            UPDATE your_table
                            SET existing_column1 = :col1, existing_column2 = :col2,
                                updated_at = CURRENT_TIMESTAMP
                            WHERE id = :record_id
                        """), {
                            "col1": safe_data.get("existing_column1"),
                            "col2": safe_data.get("existing_column2"),
                            "record_id": safe_data.get("id")
                        })
                    else:
                        # 插入操作
                        import uuid
                        new_id = str(uuid.uuid4())
                        db.execute(text("""
                            INSERT INTO your_table
                            (id, user_id, existing_column1, existing_column2, created_at, updated_at)
                            VALUES (:id, :user_id, :col1, :col2, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
                        """), {
                            "id": new_id,
                            "user_id": safe_data.get("user_id"),
                            "col1": safe_data.get("existing_column1"),
                            "col2": safe_data.get("existing_column2"),
                        })

                    db.commit()
                    return True
                else:
                    raise e
```

#### Step 4: 验证各种部署场景

**本地测试：**

```bash
# 验证迁移
python -m alembic upgrade head

# 验证模型
python -c "from open_webui.models.your_model import YourModels; print('Test OK:', YourModels.get_data())"
```

**Docker测试：**

```bash
# 构建并测试
docker-compose down
docker-compose build --no-cache
docker-compose up -d

# 验证容器内
docker exec -it open-webui python -c "from open_webui.models.your_model import YourModels; print('Docker Test OK')"
```

### 🔄 自动迁移触发机制

#### 启动时自动执行

```python
# backend/open_webui/config.py
def delayed_migration_execution():
    """延迟执行迁移，避免循环导入"""
    def run_delayed():
        time.sleep(1)  # 等待导入完成
        run_migrations()

    # 阻塞式执行，确保迁移完成后再启动应用
    migration_thread = threading.Thread(target=run_delayed, daemon=False)
    migration_thread.start()
    migration_thread.join(timeout=30)  # 最多等待30秒

# 应用启动时自动执行
delayed_migration_execution()
```

#### 三层容错策略

```python
def run_migrations():
    """运行Alembic迁移 - 三层容错"""
    try:
        from alembic import command
        from alembic.config import Config

        alembic_cfg = Config(OPEN_WEBUI_DIR / "alembic.ini")
        migrations_path = OPEN_WEBUI_DIR / "migrations"
        alembic_cfg.set_main_option("script_location", str(migrations_path))

        # 第一层：尝试合并点（解决多头问题）
        try:
            command.upgrade(alembic_cfg, "merge_heads_final")
            print("✅ 迁移成功执行到合并点")
        except Exception:
            # 第二层：尝试所有heads
            try:
                command.upgrade(alembic_cfg, "heads")
                print("✅ 迁移成功执行到所有heads")
            except Exception:
                # 第三层：最后尝试单head
                command.upgrade(alembic_cfg, "head")
                print("✅ 迁移成功执行到head")

    except Exception as e:
        print(f"⚠️ Alembic迁移失败: {e}")
        # Fallback: 直接创建表结构
        try:
            from open_webui.internal.db import engine, Base
            Base.metadata.create_all(bind=engine)
            print("✅ 数据库表直接创建成功")
        except Exception as create_error:
            print(f"❌ 表创建也失败: {create_error}")
            raise create_error
```

### 📋 新功能开发检查清单

#### 迁移文件检查

- [ ] 迁移文件使用描述性名称
- [ ] 检查表/列存在性避免重复创建
- [ ] 新列设置 `nullable=True`
- [ ] 避免删除表或列操作
- [ ] 包含适当的日志输出

#### 模型层检查

- [ ] ORM查询包装在 try/except 中
- [ ] 检测 "no such column" 错误
- [ ] 提供原生SQL兼容查询
- [ ] 为缺失字段设置合理默认值
- [ ] 包含详细的日志记录

#### 测试验证检查

- [ ] 本地环境测试（全新+更新）
- [ ] Docker环境测试
- [ ] 向后兼容性验证
- [ ] 性能影响评估
- [ ] 文档更新

### 🚨 注意事项

1. **数据安全原则**
   - 永远不要删除表或列
   - 新列必须允许NULL值
   - 充分测试后再部署

2. **兼容性优先**
   - 所有新功能必须向后兼容
   - 旧版本数据库也能正常运行
   - 渐进式功能启用

3. **监控和日志**
   - 记录迁移执行过程
   - 监控兼容模式的使用情况
   - 及时发现和解决问题

这套标准化流程确保新功能添加时的数据安全和系统稳定性。
